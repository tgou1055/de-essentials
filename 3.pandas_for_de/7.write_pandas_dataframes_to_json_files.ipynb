{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get column names from schemas.json\n",
    "def get_column_names(schemas: dict, ds_name: str, sorting_key='column_position'):\n",
    "    column_details = schemas[ds_name]\n",
    "    columns = sorted(column_details, key=lambda col: col[sorting_key], reverse=False)\n",
    "    return [col['column_name'] for col in columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the schemas as a dict through json\n",
    "schemas = json.load(open('../data/retail_db/schemas.json'))\n",
    "# Obtain order column names\n",
    "orders_columns = get_column_names(schemas, 'orders')\n",
    "# Read orders data from csv file based on orders_column names\n",
    "orders = pd.read_csv('../data/retail_db/orders/part-00000', names=orders_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0morders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mna_rep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfloat_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | Callable | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Sequence[Hashable] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool_t | list[str]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool_t'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'IndexLabel | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CompressionOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool_t'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'OpenFileErrors'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'StorageOptions | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'str | None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Write object to a comma-separated values (csv) file.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "path_or_buf : str, path object, file-like object, or None, default None\n",
      "    String, path object (implementing os.PathLike[str]), or file-like\n",
      "    object implementing a write() function. If None, the result is\n",
      "    returned as a string. If a non-binary file object is passed, it should\n",
      "    be opened with `newline=''`, disabling universal newlines. If a binary\n",
      "    file object is passed, `mode` might need to contain a `'b'`.\n",
      "sep : str, default ','\n",
      "    String of length 1. Field delimiter for the output file.\n",
      "na_rep : str, default ''\n",
      "    Missing data representation.\n",
      "float_format : str, Callable, default None\n",
      "    Format string for floating point numbers. If a Callable is given, it takes\n",
      "    precedence over other numeric formatting parameters, like decimal.\n",
      "columns : sequence, optional\n",
      "    Columns to write.\n",
      "header : bool or list of str, default True\n",
      "    Write out the column names. If a list of strings is given it is\n",
      "    assumed to be aliases for the column names.\n",
      "index : bool, default True\n",
      "    Write row names (index).\n",
      "index_label : str or sequence, or False, default None\n",
      "    Column label for index column(s) if desired. If None is given, and\n",
      "    `header` and `index` are True, then the index names are used. A\n",
      "    sequence should be given if the object uses MultiIndex. If\n",
      "    False do not print fields for index names. Use index_label=False\n",
      "    for easier importing in R.\n",
      "mode : {'w', 'x', 'a'}, default 'w'\n",
      "    Forwarded to either `open(mode=)` or `fsspec.open(mode=)` to control\n",
      "    the file opening. Typical values include:\n",
      "\n",
      "    - 'w', truncate the file first.\n",
      "    - 'x', exclusive creation, failing if the file already exists.\n",
      "    - 'a', append to the end of file if it exists.\n",
      "\n",
      "encoding : str, optional\n",
      "    A string representing the encoding to use in the output file,\n",
      "    defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      "    is a non-binary file object.\n",
      "compression : str or dict, default 'infer'\n",
      "    For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      "    path-like, then detect compression from the following extensions: '.gz',\n",
      "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "    (otherwise no compression).\n",
      "    Set to ``None`` for no compression.\n",
      "    Can also be a dict with key ``'method'`` set\n",
      "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "    other key-value pairs are forwarded to\n",
      "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "    ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      "    ``tarfile.TarFile``, respectively.\n",
      "    As an example, the following could be passed for faster compression and to create\n",
      "    a reproducible gzip archive:\n",
      "    ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "        Added support for `.tar` files.\n",
      "\n",
      "       May be a dict with key 'method' as compression mode\n",
      "       and other entries as additional compression options if\n",
      "       compression mode is 'zip'.\n",
      "\n",
      "       Passing compression options as keys in dict is\n",
      "       supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      "quoting : optional constant from csv module\n",
      "    Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "    then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "    will treat them as non-numeric.\n",
      "quotechar : str, default '\\\"'\n",
      "    String of length 1. Character used to quote fields.\n",
      "lineterminator : str, optional\n",
      "    The newline character or character sequence to use in the output\n",
      "    file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "    this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      "\n",
      "    .. versionchanged:: 1.5.0\n",
      "\n",
      "        Previously was line_terminator, changed for consistency with\n",
      "        read_csv and the standard library 'csv' module.\n",
      "\n",
      "chunksize : int or None\n",
      "    Rows to write at a time.\n",
      "date_format : str, default None\n",
      "    Format string for datetime objects.\n",
      "doublequote : bool, default True\n",
      "    Control quoting of `quotechar` inside a field.\n",
      "escapechar : str, default None\n",
      "    String of length 1. Character used to escape `sep` and `quotechar`\n",
      "    when appropriate.\n",
      "decimal : str, default '.'\n",
      "    Character recognized as decimal separator. E.g. use ',' for\n",
      "    European data.\n",
      "errors : str, default 'strict'\n",
      "    Specifies how encoding and decoding errors are to be handled.\n",
      "    See the errors argument for :func:`open` for a full list\n",
      "    of options.\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "    details, and for more examples on storage options refer `here\n",
      "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "    highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "None or str\n",
      "    If path_or_buf is None, returns the resulting csv format as a\n",
      "    string. Otherwise returns None.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "read_csv : Load a CSV file into a DataFrame.\n",
      "to_excel : Write DataFrame to an Excel file.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Create 'out.csv' containing 'df' without indices\n",
      "\n",
      ">>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "...                    'mask': ['red', 'purple'],\n",
      "...                    'weapon': ['sai', 'bo staff']})\n",
      ">>> df.to_csv('out.csv', index=False)  # doctest: +SKIP\n",
      "\n",
      "Create 'out.zip' containing 'out.csv'\n",
      "\n",
      ">>> df.to_csv(index=False)\n",
      "'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      ">>> compression_opts = dict(method='zip',\n",
      "...                         archive_name='out.csv')  # doctest: +SKIP\n",
      ">>> df.to_csv('out.zip', index=False,\n",
      "...           compression=compression_opts)  # doctest: +SKIP\n",
      "\n",
      "To write a csv file to a new folder or nested folder you will first\n",
      "need to create it using either Pathlib or os:\n",
      "\n",
      ">>> from pathlib import Path  # doctest: +SKIP\n",
      ">>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      ">>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      ">>> df.to_csv(filepath)  # doctest: +SKIP\n",
      "\n",
      ">>> import os  # doctest: +SKIP\n",
      ">>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      ">>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/share/virtualenvs/de-essentials-C4UFkHK6/lib/python3.12/site-packages/pandas/core/generic.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "orders.to_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m511\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "makedirs(name [, mode=0o777][, exist_ok=False])\n",
      "\n",
      "Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n",
      "mkdir, except that any intermediate path segment (not just the rightmost)\n",
      "will be created if it does not exist. If the target directory already\n",
      "exists, raise an OSError if exist_ok is False. Otherwise no exception is\n",
      "raised.  This is recursive.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/de-essentials/3.pandas_for_de/<frozen os>\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "os.makedirs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory if it does not exist.\n",
    "os.makedirs('../data/retail_db/orders_json', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnar format as JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores using columnar format as JSON file\n",
    "# Review data in the files to understand how data is formatted\n",
    "orders.to_json('../data/retail_db/orders_json/part-00000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data using row format\n",
    "orders.to_json(\n",
    "    '../data/retail_db/orders_json/part-00000',\n",
    "    orient = 'records',\n",
    "    lines = True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-essentials-C4UFkHK6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
